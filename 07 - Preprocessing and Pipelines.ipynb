{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Pipelines\n",
    "============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validated pipelines including scaling, we need to estimate mean and standard deviation separately for each fold.\n",
    "To do that, we build a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"svm\", SVC())])\n",
    "# in new versions: make_pipeline(StandardScaler(), SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 0, 9, 7, 4, 9, 0, 9, 1, 6, 6, 8, 3, 2, 9, 7, 5, 9, 1, 1, 4, 9,\n",
       "       1, 4, 2, 8, 5, 2, 3, 6, 2, 5, 3, 3, 3, 8, 8, 5, 8, 8, 7, 7, 8, 6, 9,\n",
       "       9, 4, 8, 4, 4, 0, 9, 6, 2, 7, 2, 1, 3, 3, 1, 8, 6, 0, 8, 3, 1, 0, 0,\n",
       "       4, 9, 1, 5, 9, 6, 5, 0, 0, 3, 2, 9, 4, 6, 9, 8, 2, 2, 5, 3, 8, 0, 4,\n",
       "       5, 2, 5, 7, 0, 9, 5, 0, 1, 1, 7, 5, 3, 9, 2, 0, 8, 3, 5, 9, 0, 8, 5,\n",
       "       9, 6, 3, 4, 0, 7, 5, 3, 9, 4, 4, 9, 4, 1, 0, 7, 4, 0, 4, 8, 7, 6, 3,\n",
       "       6, 5, 0, 4, 5, 6, 6, 8, 8, 1, 1, 2, 8, 4, 5, 0, 5, 1, 7, 6, 4, 6, 5,\n",
       "       8, 4, 1, 1, 9, 2, 3, 5, 4, 9, 5, 4, 5, 0, 1, 0, 9, 3, 0, 7, 8, 3, 9,\n",
       "       8, 8, 3, 1, 6, 0, 3, 4, 0, 8, 0, 9, 1, 9, 8, 5, 6, 7, 9, 8, 2, 1, 3,\n",
       "       9, 3, 4, 6, 8, 8, 0, 6, 5, 6, 9, 5, 8, 3, 4, 2, 9, 3, 8, 1, 0, 9, 9,\n",
       "       1, 5, 1, 5, 9, 6, 2, 2, 5, 1, 4, 3, 2, 3, 9, 5, 0, 8, 7, 0, 6, 6, 8,\n",
       "       7, 0, 6, 6, 3, 5, 1, 8, 8, 3, 6, 4, 8, 3, 6, 1, 0, 9, 8, 3, 2, 3, 1,\n",
       "       5, 3, 7, 6, 5, 7, 5, 1, 1, 5, 4, 8, 4, 0, 9, 9, 3, 9, 2, 9, 5, 9, 6,\n",
       "       5, 2, 8, 2, 7, 9, 7, 3, 7, 6, 0, 3, 1, 3, 8, 5, 8, 1, 4, 7, 7, 0, 7,\n",
       "       6, 4, 0, 0, 4, 1, 4, 0, 1, 4, 6, 5, 6, 7, 7, 6, 8, 9, 8, 7, 4, 0, 9,\n",
       "       9, 4, 4, 8, 8, 1, 2, 9, 8, 1, 6, 6, 0, 8, 5, 2, 6, 9, 2, 7, 9, 2, 0,\n",
       "       7, 6, 0, 0, 8, 5, 4, 4, 6, 5, 7, 5, 5, 2, 8, 0, 1, 1, 9, 6, 3, 1, 5,\n",
       "       2, 7, 8, 0, 9, 6, 5, 1, 7, 5, 3, 5, 8, 2, 7, 1, 2, 5, 6, 3, 5, 6, 9,\n",
       "       0, 3, 9, 9, 6, 4, 7, 4, 0, 5, 9, 4, 3, 7, 2, 0, 0, 0, 2, 8, 4, 7, 5,\n",
       "       5, 7, 5, 8, 9, 7, 1, 9, 4, 6, 6, 7, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation with a pipeline\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96902655,  0.98218263,  0.96860987])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search with a pipeline\n",
    "==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {'svm__C': 10. ** np.arange(-3, 3),\n",
    "              'svm__gamma' : 10. ** np.arange(-3, 3)}\n",
    "\n",
    "grid_pipeline = GridSearchCV(pipeline, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
       "       param_grid={'svm__C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,\n",
       "         1.00000e+01,   1.00000e+02]), 'svm__gamma': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,\n",
       "         1.00000e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97777777777777775"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
